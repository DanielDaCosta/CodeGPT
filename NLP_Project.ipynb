{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac4a9908096742ef9f67e6353f72c672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cde20f7ee21f4622a9c021e2418d5b99",
              "IPY_MODEL_d7a4875c5024484095eb87d88ebbdc3f",
              "IPY_MODEL_c6a3474276f3459399927f915728ef6c"
            ],
            "layout": "IPY_MODEL_0dc6406fa15e4dd9984ee4aa16e0c648"
          }
        },
        "cde20f7ee21f4622a9c021e2418d5b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49117ad0c494cec9c14a6444c9d74f1",
            "placeholder": "​",
            "style": "IPY_MODEL_e00764f812c54c27ba16d531f21fd4c7",
            "value": "100%"
          }
        },
        "d7a4875c5024484095eb87d88ebbdc3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a22af7b578ee4f5ba57f5bd155a731e5",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78e996228d3c4b6b9bea79b105591ebe",
            "value": 4
          }
        },
        "c6a3474276f3459399927f915728ef6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0df8fee6ab64a70bcba8c63b8e56f0e",
            "placeholder": "​",
            "style": "IPY_MODEL_ed3d49ec69d04d5e9749be0fe4a36078",
            "value": " 4/4 [00:00&lt;00:00, 55.76it/s]"
          }
        },
        "0dc6406fa15e4dd9984ee4aa16e0c648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49117ad0c494cec9c14a6444c9d74f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00764f812c54c27ba16d531f21fd4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a22af7b578ee4f5ba57f5bd155a731e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e996228d3c4b6b9bea79b105591ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0df8fee6ab64a70bcba8c63b8e56f0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed3d49ec69d04d5e9749be0fe4a36078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-BKDHy5LE68",
        "outputId": "a101e068-da30-4bb1-a797-48bf3e8d2d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "!pip install transformers\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"  # reduce the amount of console output from TF\n",
        "import tensorflow as tf\n",
        "from transformers import *\n",
        "!pip install -q datasets # install HF datasets library\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "logging.set_verbosity_warning()\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('TF version',tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'))) # check GPU available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55Fv2pA-LKPY",
        "outputId": "c097854c-72ec-451e-9890-2f9328cdbcc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version 2.12.0\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV9QRpAbbJCh",
        "outputId": "7feb81f3-9da6-4039-8e5b-5ce99d0770d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "xH-Y1px0OI-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_full = load_dataset(\"mbpp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "ac4a9908096742ef9f67e6353f72c672",
            "cde20f7ee21f4622a9c021e2418d5b99",
            "d7a4875c5024484095eb87d88ebbdc3f",
            "c6a3474276f3459399927f915728ef6c",
            "0dc6406fa15e4dd9984ee4aa16e0c648",
            "f49117ad0c494cec9c14a6444c9d74f1",
            "e00764f812c54c27ba16d531f21fd4c7",
            "a22af7b578ee4f5ba57f5bd155a731e5",
            "78e996228d3c4b6b9bea79b105591ebe",
            "e0df8fee6ab64a70bcba8c63b8e56f0e",
            "ed3d49ec69d04d5e9749be0fe4a36078"
          ]
        },
        "id": "6stJ4jvJZSev",
        "outputId": "c19d6d33-eb12-40a4-c094-3f2b6a24bee5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:No config specified, defaulting to: mbpp/full\n",
            "WARNING:datasets.builder:Found cached dataset mbpp (/root/.cache/huggingface/datasets/mbpp/full/1.0.2/4458a31cd4305553c8e88e3f0bfb94fc74fe1a9faeeb8c32ed166939735eaeff)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac4a9908096742ef9f67e6353f72c672"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = dataset_full['test']"
      ],
      "metadata": {
        "id": "cpxsLB3tOKWk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtPQFUanRr9b",
        "outputId": "30eee4f5-c99b-4b68-a451-1b0a5126dc58"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'task_id': 14,\n",
              " 'text': 'Write a python function to find the volume of a triangular prism.',\n",
              " 'code': 'def find_Volume(l,b,h) : \\r\\n    return ((l * b * h) / 2) ',\n",
              " 'test_list': ['assert find_Volume(10,8,6) == 240',\n",
              "  'assert find_Volume(3,2,2) == 6',\n",
              "  'assert find_Volume(1,2,1) == 1'],\n",
              " 'test_setup_code': '',\n",
              " 'challenge_test_list': []}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model codet5-large-ntp-py"
      ],
      "metadata": {
        "id": "j85ZVc6ZOcOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-large-ntp-py\")"
      ],
      "metadata": {
        "id": "C9B0NTq3ONIL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-large-ntp-py\").to(device);"
      ],
      "metadata": {
        "id": "C9uBGf0VOhkY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def make_prediction(model, input_ids: list, max_length=128):\n",
        "#   outputs = model.generate(input_ids, max_length=max_length)\n",
        "#   return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "xxcbOFBFOjm6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Example 1: Few-shot"
      ],
      "metadata": {
        "id": "f_oP8-x6OskO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Write a python function to remove first and last occurrence of a given character from the string. Your code should satisfy these tests:\\n assert remove_Occ(\"hello\",\"l\") == \"heo\"\\n assert remove_Occ(\"abcda\",\"a\") == \"bcd\"\\n assert remove_Occ(\"PHP\",\"P\") == \"H\" \"\"\""
      ],
      "metadata": {
        "id": "UIi0xLX5OuGd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "jvHTn-yWV7xV",
        "outputId": "511c7c02-6996-44a4-cb2c-260f9b2c0b99"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Write a python function to remove first and last occurrence of a given character from the string. Your code should satisfy these tests:\\n assert remove_Occ(\"hello\",\"l\") == \"heo\"\\n assert remove_Occ(\"abcda\",\"a\") == \"bcd\"\\n assert remove_Occ(\"PHP\",\"P\") == \"H\" '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = tokenizer(text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "sWwwuj4SPSGZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Example 2: Few-shot"
      ],
      "metadata": {
        "id": "SlGtzC1XXT8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = test_set[1]['text'] + ' Your code should satisfy these tests:\\n' +'\\n'.join(test_set[1]['test_list'])"
      ],
      "metadata": {
        "id": "mn3riX5VPW46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "rIVx050EXQhr",
        "outputId": "bcaa5abf-89ad-46ce-9f6f-40287e1a8b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Write a function to sort a given matrix in ascending order according to the sum of its rows. Your code should satisfy these tests:\\nassert sort_matrix([[1, 2, 3], [2, 4, 5], [1, 1, 1]])==[[1, 1, 1], [1, 2, 3], [2, 4, 5]]\\nassert sort_matrix([[1, 2, 3], [-2, 4, -5], [1, -1, 1]])==[[-2, 4, -5], [1, -1, 1], [1, 2, 3]]\\nassert sort_matrix([[5,8,9],[6,4,3],[2,1,4]])==[[2, 1, 4], [6, 4, 3], [5, 8, 9]]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Example 3: Pass@k"
      ],
      "metadata": {
        "id": "XD5Sa1qBbFea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Write a python function to remove first and last occurrence of a given character from the string. Your code should satisfy these tests:\\n assert remove_Occ(\"hello\",\"l\") == \"heo\"\\n assert remove_Occ(\"abcda\",\"a\") == \"bcd\"\\n assert remove_Occ(\"PHP\",\"P\") == \"H\" \"\"\""
      ],
      "metadata": {
        "id": "DUPt5ZOybFEB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model_inputs = tokenizer(text, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "id": "e6O78c-YbODQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d023630a-8efc-43ec-e7dc-1520911f3fe8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.08 ms, sys: 18 µs, total: 1.1 ms\n",
            "Wall time: 1.12 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output_1 = model.generate(model_inputs.input_ids, max_length=128)"
      ],
      "metadata": {
        "id": "6cpHInCEUg1b"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "output_2 = model.generate(model_inputs.input_ids, max_length=128, num_beams=80, num_return_sequences=80, early_stopping=True)\n",
        "  # return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIX-VDWvdNgp",
        "outputId": "37446ad5-7fd5-4cd8-a97d-29608220c317"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.7 s, sys: 58.7 ms, total: 2.76 s\n",
            "Wall time: 2.87 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "output_2 = model.generate(model_inputs.input_ids, max_length=128, num_beams=80, num_return_sequences=80, early_stopping=True)\n",
        "  # return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "_K34YBv8UINr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bcdcee-1582-4e1c-b817-1e04e75f4bed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 41s, sys: 1.22 s, total: 1min 42s\n",
            "Wall time: 2min 10s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # now we have 3 output sequences\n",
        "# print(\"Output:\\n\")\n",
        "# list_of_outputs = []\n",
        "# for i, beam_output in enumerate(output_2):\n",
        "#   output = tokenizer.decode(beam_output, skip_special_tokens=True)\n",
        "#   list_of_outputs.append(output)\n",
        "#   print(\"{}: {}\".format(i, output))"
      ],
      "metadata": {
        "id": "xeh4M8pBbQ2H"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exec(\"\"\"def remove_Occ(string, char):\n",
        "#     return string[1:-1].replace(char, \"\")\"\"\")"
      ],
      "metadata": {
        "id": "LYyoKu6WXc1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exec('assert remove_Occ(\"hello\",\"l\") == \"heo\"')"
      ],
      "metadata": {
        "id": "N1XoDIyAXrYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "OnNZjWIFe-29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "3LlWSIedo_8L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVgIaIGCjUPB",
        "outputId": "74ea9c48-512a-4d86-d49e-aed9bbdfc159"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max length on test set\n",
        "max([len(i['code'])for i in test_set])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDoxae_-twtp",
        "outputId": "a28d9136-1858-4af7-826e-d85120229976"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1331"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(model, input_ids: list, max_length=128, batch=False,**kwargs):\n",
        "  outputs = model.generate(input_ids, max_length=max_length, **kwargs)\n",
        "  if batch:\n",
        "    outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "  else:\n",
        "    outputs = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  return outputs"
      ],
      "metadata": {
        "id": "KSE9n3Hnkw6M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_output(output_file: str, data: list, header):\n",
        "  # Create file if it doesn't exist\n",
        "  if not os.path.exists(output_file):\n",
        "    with open(output_file, \"a+\", encoding='utf-8') as f:\n",
        "        write = csv.writer(f)\n",
        "        write.writerows([header])\n",
        "  results_df = pd.DataFrame.from_records(data, columns=header)\n",
        "  results_df.to_csv(output_file, mode='a', index=False, header=None)"
      ],
      "metadata": {
        "id": "mM_XbdqysR57"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Single Prection"
      ],
      "metadata": {
        "id": "J6Jm84YsjEeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAX_LENGTH = 1331\n",
        "results = []\n",
        "# list_of_inputs = []\n",
        "# list_of_true_labels = []\n",
        "# list_of_predictions = []\n",
        "full_path = '/content/drive/MyDrive/CSCI544/Project'\n",
        "model_name = 'codet5-large-ntp-py'\n",
        "output_file = f\"{full_path}/{model_name}-pred.csv\"\n",
        "for sample in test_set:\n",
        "  task_id = sample['task_id']\n",
        "  example = sample['text']\n",
        "  true_label = sample['code']\n",
        "  max_length = len(true_label)\n",
        "  inputs = example + ' Your code should satisfy these tests:\\n ' +'\\n '.join(sample['test_list'])\n",
        "  model_inputs = tokenizer(inputs, return_tensors=\"pt\") # prediction with same lengh as output\n",
        "  output = make_prediction(model, model_inputs.input_ids, max_length=max_length)\n",
        "  # list_of_inputs.append([inputs]) \n",
        "  # list_of_predictions.append([output])\n",
        "  # list_of_true_labels.append([true_label])\n",
        "  result = [{'task_id': task_id, 'text': example, 'test_list': sample['test_list'],\n",
        "             'input': inputs, 'true_label': true_label, 'prediction': output}]\n",
        "  results.append(result)\n",
        "  save_output(output_file, result)\n",
        "  # break"
      ],
      "metadata": {
        "id": "vIemqjg3j4Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Multiple Predictions (num_return_sequences)"
      ],
      "metadata": {
        "id": "drmvJ8EpjHyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Model on GPU?: ', next(model.parameters()).is_cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuSHwbXLlpIO",
        "outputId": "f5c437b8-7df0-46eb-f16c-315b4eb08e2f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model on GPU?:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MAX_LENGTH = 1331\n",
        "results = []\n",
        "# list_of_inputs = []\n",
        "# list_of_true_labels = []\n",
        "# list_of_predictions = []\n",
        "full_path = '/content/gdrive/MyDrive/CSCI544/Project'\n",
        "model_name = 'codet5-large-ntp-py-multiple-sentences-2'\n",
        "output_file = f\"{full_path}/{model_name}-pred.csv\"\n",
        "for sample in test_set:\n",
        "  task_id = sample['task_id']\n",
        "  example = sample['text']\n",
        "  true_label = sample['code']\n",
        "  max_length = len(true_label)\n",
        "  inputs = example + ' Your code should satisfy these tests:\\n ' +'\\n '.join(sample['test_list'])\n",
        "  model_inputs = tokenizer(inputs, return_tensors=\"pt\").to(device) # prediction with same lengh as output\n",
        "  output = make_prediction(model, model_inputs.input_ids, max_length=max_length, batch=True,\n",
        "                           num_beams=80, num_return_sequences=80, early_stopping=True)\n",
        "  del model_inputs\n",
        "  # list_of_inputs.append([inputs]) \n",
        "  # list_of_predictions.append([output])\n",
        "  # list_of_true_labels.append([true_label])\n",
        "  result = [{'task_id': task_id, 'text': example, 'test_list': sample['test_list'],\n",
        "             'input': inputs, 'true_label': true_label, 'prediction': output}]\n",
        "  results.append(result)\n",
        "  save_output(output_file, result, header=['task_id', 'text', 'test_list',\n",
        "             'input', 'true_label', 'prediction'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "M-z1L21ms0xI",
        "outputId": "ef116593-ff2e-4553-f20e-3ffcd049c350"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fbcd1105c1da>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' Your code should satisfy these tests:\\n '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'\\n '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# prediction with same lengh as output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   output = make_prediction(model, model_inputs.input_ids, max_length=max_length, batch=True,\n\u001b[0m\u001b[1;32m     17\u001b[0m                            num_beams=80, num_return_sequences=80, early_stopping=True)\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-972216c98098>\u001b[0m in \u001b[0;36mmake_prediction\u001b[0;34m(model, input_ids, max_length, batch, **kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m             )\n\u001b[1;32m   1523\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1525\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2808\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2810\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2811\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2812\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1717\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 )\n\u001b[1;32m   1085\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1087\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    598\u001b[0m     ):\n\u001b[1;32m    599\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         attention_output = self.SelfAttention(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;31m# get key/value states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         key_states = project(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_value_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(hidden_states, proj_layer, key_value_states, past_key_value)\u001b[0m\n\u001b[1;32m    504\u001b[0m                     \u001b[0;31m# self-attn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                     \u001b[0;31m# (batch_size, n_heads, key_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                     \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mkey_value_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                     \u001b[0;31m# checking that the `sequence_length` of the `past_key_value` is the same as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 14.75 GiB total capacity; 13.07 GiB already allocated; 14.81 MiB free; 13.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TFyEPU3p0ZW"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "_R3bTLREh4LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger('Evaluation')\n",
        "\n",
        "logger.setLevel(logging.DEBUG)# allow DEBUG level messages to pass through the logger"
      ],
      "metadata": {
        "id": "1fO3qvNHSU02"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "recursion_limit = sys.getrecursionlimit()\n",
        "print(f\"Current recursion limit: {recursion_limit}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdPHTk8rkHTL",
        "outputId": "ecd677b8-5984-4f05-d75c-03e1de363a18"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current recursion limit: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9aUwR8fU2CB",
        "outputId": "3f392980-e1c1-4330-cb40-5845bceb8321"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_path = '/content/drive/MyDrive/CSCI544/Project'\n",
        "model_name = 'codet5-large-ntp-py'\n",
        "output_file = f\"{full_path}/{model_name}-pred.csv\""
      ],
      "metadata": {
        "id": "koBVwFbTRXz4"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/CSCI544/Project/codet5-large-ntp-py-pred.csv')"
      ],
      "metadata": {
        "id": "YdCkt0hWo-wS"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df[['true_label', 'prediction']].values"
      ],
      "metadata": {
        "id": "wyi30Om8Zrc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bleu Score"
      ],
      "metadata": {
        "id": "2fOKGG3qcmJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_bleu_score(sentences: np.array) -> float:\n",
        "  n_rows = sentences.shape[0]\n",
        "  bleu_scores = []\n",
        "  max_ngram_size = 4\n",
        "\n",
        "  # define the smoothing function\n",
        "  smooth_fn = SmoothingFunction() # Smoothing method 1: Add epsilon counts to precision with 0 counts.\n",
        "\n",
        "  for i in range(n_rows):\n",
        "    reference = sentences[i][0] # true label\n",
        "    candidate = sentences[i][1] # prediction\n",
        "    # Tokenize\n",
        "    true_token = word_tokenize(reference)\n",
        "    pred_token = word_tokenize(candidate)\n",
        "    score = nltk.translate.bleu_score.sentence_bleu(\n",
        "        [true_token], pred_token, weights=[1./max_ngram_size]*max_ngram_size,\n",
        "        smoothing_function=smooth_fn.method1)\n",
        "    bleu_scores.append(score)\n",
        "\n",
        "  # compute the average BLEU score over all candidate sentences\n",
        "  avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "  return avg_bleu_score\n"
      ],
      "metadata": {
        "id": "GRcneQVQb7d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Bleu Score: ', compute_bleu_score(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBrVEHercb3a",
        "outputId": "4f6a14a2-2159-4c05-b875-780ecb032d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu Score:  0.10143968640805599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Synthesis Performance"
      ],
      "metadata": {
        "id": "XsxDHDjmcw34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = df[['task_id', 'test_list','true_label', 'prediction']].values"
      ],
      "metadata": {
        "id": "dI_5IW3xZo4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exec('assert 2 == 2')"
      ],
      "metadata": {
        "id": "QmBILBB2cF2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list = []\n",
        "error_messages = []\n",
        "result = []\n",
        "logger.info('Starting loop')\n",
        "\n",
        "for i, row in enumerate(rows):\n",
        "  task_id, test_list, true_label, prediction = row\n",
        "  logger.info(f'Processing item {i+1} of {len(rows)}. Task_id: {task_id}')\n",
        "  test_list = eval(test_list) # evaluate the string representation of each list as a Python expression\n",
        "  # Get code after 'def'\n",
        "  def_index = prediction.find('def')  # find the index of the 'def' keyword\n",
        "  function_def = prediction[def_index:]  # extract the substring starting from 'def'\n",
        "\n",
        "  error_list = []\n",
        "  count_success = 0\n",
        "  try:\n",
        "    if task_id != 45:   \n",
        "      exec(function_def)\n",
        "      for i, test in enumerate(test_list):\n",
        "        try:\n",
        "          exec(test)\n",
        "          error_list.append(f'Test {i} Success')\n",
        "          count_success += 1\n",
        "        except Exception as e:\n",
        "          # print(type(e))\n",
        "          error_list.append(f'Test {i} {type(e)}: {e}')\n",
        "    else:\n",
        "      error_list.append(f'Test {i}: Recursion problem')\n",
        "\n",
        "  except Exception as e:\n",
        "    error_list.append(f'{type(e)}: {e}')\n",
        "  acc_list.append(count_success/len(test_list))\n",
        "  error_messages.append(error_list)\n",
        "  result.append(\n",
        "      {'task_id': task_id, 'test_list': test_list, 'true_label': true_label,\n",
        "       'prediction': prediction, 'successful_test_cases': count_success,\n",
        "       'error_list': error_list})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COEDNX43aORV",
        "outputId": "2877ef3d-23d6-425d-e4b8-cecb22bc0dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Evaluation:Starting loop\n",
            "INFO:Evaluation:Processing item 1 of 500. Task_id: 11\n",
            "INFO:Evaluation:Processing item 2 of 500. Task_id: 12\n",
            "INFO:Evaluation:Processing item 3 of 500. Task_id: 13\n",
            "INFO:Evaluation:Processing item 4 of 500. Task_id: 14\n",
            "INFO:Evaluation:Processing item 5 of 500. Task_id: 15\n",
            "INFO:Evaluation:Processing item 6 of 500. Task_id: 16\n",
            "INFO:Evaluation:Processing item 7 of 500. Task_id: 17\n",
            "INFO:Evaluation:Processing item 8 of 500. Task_id: 18\n",
            "INFO:Evaluation:Processing item 9 of 500. Task_id: 19\n",
            "INFO:Evaluation:Processing item 10 of 500. Task_id: 20\n",
            "INFO:Evaluation:Processing item 11 of 500. Task_id: 21\n",
            "INFO:Evaluation:Processing item 12 of 500. Task_id: 22\n",
            "INFO:Evaluation:Processing item 13 of 500. Task_id: 23\n",
            "INFO:Evaluation:Processing item 14 of 500. Task_id: 24\n",
            "INFO:Evaluation:Processing item 15 of 500. Task_id: 25\n",
            "INFO:Evaluation:Processing item 16 of 500. Task_id: 26\n",
            "INFO:Evaluation:Processing item 17 of 500. Task_id: 27\n",
            "INFO:Evaluation:Processing item 18 of 500. Task_id: 28\n",
            "INFO:Evaluation:Processing item 19 of 500. Task_id: 29\n",
            "INFO:Evaluation:Processing item 20 of 500. Task_id: 30\n",
            "INFO:Evaluation:Processing item 21 of 500. Task_id: 31\n",
            "INFO:Evaluation:Processing item 22 of 500. Task_id: 32\n",
            "INFO:Evaluation:Processing item 23 of 500. Task_id: 33\n",
            "INFO:Evaluation:Processing item 24 of 500. Task_id: 34\n",
            "INFO:Evaluation:Processing item 25 of 500. Task_id: 35\n",
            "INFO:Evaluation:Processing item 26 of 500. Task_id: 36\n",
            "INFO:Evaluation:Processing item 27 of 500. Task_id: 37\n",
            "INFO:Evaluation:Processing item 28 of 500. Task_id: 38\n",
            "INFO:Evaluation:Processing item 29 of 500. Task_id: 39\n",
            "INFO:Evaluation:Processing item 30 of 500. Task_id: 40\n",
            "INFO:Evaluation:Processing item 31 of 500. Task_id: 41\n",
            "INFO:Evaluation:Processing item 32 of 500. Task_id: 42\n",
            "INFO:Evaluation:Processing item 33 of 500. Task_id: 43\n",
            "INFO:Evaluation:Processing item 34 of 500. Task_id: 44\n",
            "INFO:Evaluation:Processing item 35 of 500. Task_id: 45\n",
            "INFO:Evaluation:Processing item 36 of 500. Task_id: 46\n",
            "INFO:Evaluation:Processing item 37 of 500. Task_id: 47\n",
            "INFO:Evaluation:Processing item 38 of 500. Task_id: 48\n",
            "INFO:Evaluation:Processing item 39 of 500. Task_id: 49\n",
            "INFO:Evaluation:Processing item 40 of 500. Task_id: 50\n",
            "INFO:Evaluation:Processing item 41 of 500. Task_id: 51\n",
            "INFO:Evaluation:Processing item 42 of 500. Task_id: 52\n",
            "INFO:Evaluation:Processing item 43 of 500. Task_id: 53\n",
            "INFO:Evaluation:Processing item 44 of 500. Task_id: 54\n",
            "INFO:Evaluation:Processing item 45 of 500. Task_id: 55\n",
            "INFO:Evaluation:Processing item 46 of 500. Task_id: 56\n",
            "INFO:Evaluation:Processing item 47 of 500. Task_id: 57\n",
            "INFO:Evaluation:Processing item 48 of 500. Task_id: 58\n",
            "INFO:Evaluation:Processing item 49 of 500. Task_id: 59\n",
            "INFO:Evaluation:Processing item 50 of 500. Task_id: 60\n",
            "INFO:Evaluation:Processing item 51 of 500. Task_id: 61\n",
            "INFO:Evaluation:Processing item 52 of 500. Task_id: 62\n",
            "INFO:Evaluation:Processing item 53 of 500. Task_id: 63\n",
            "INFO:Evaluation:Processing item 54 of 500. Task_id: 64\n",
            "INFO:Evaluation:Processing item 55 of 500. Task_id: 65\n",
            "INFO:Evaluation:Processing item 56 of 500. Task_id: 66\n",
            "INFO:Evaluation:Processing item 57 of 500. Task_id: 67\n",
            "INFO:Evaluation:Processing item 58 of 500. Task_id: 68\n",
            "INFO:Evaluation:Processing item 59 of 500. Task_id: 69\n",
            "INFO:Evaluation:Processing item 60 of 500. Task_id: 70\n",
            "INFO:Evaluation:Processing item 61 of 500. Task_id: 71\n",
            "INFO:Evaluation:Processing item 62 of 500. Task_id: 72\n",
            "INFO:Evaluation:Processing item 63 of 500. Task_id: 73\n",
            "INFO:Evaluation:Processing item 64 of 500. Task_id: 74\n",
            "INFO:Evaluation:Processing item 65 of 500. Task_id: 75\n",
            "INFO:Evaluation:Processing item 66 of 500. Task_id: 76\n",
            "INFO:Evaluation:Processing item 67 of 500. Task_id: 77\n",
            "INFO:Evaluation:Processing item 68 of 500. Task_id: 78\n",
            "INFO:Evaluation:Processing item 69 of 500. Task_id: 79\n",
            "INFO:Evaluation:Processing item 70 of 500. Task_id: 80\n",
            "INFO:Evaluation:Processing item 71 of 500. Task_id: 81\n",
            "INFO:Evaluation:Processing item 72 of 500. Task_id: 82\n",
            "INFO:Evaluation:Processing item 73 of 500. Task_id: 83\n",
            "INFO:Evaluation:Processing item 74 of 500. Task_id: 84\n",
            "INFO:Evaluation:Processing item 75 of 500. Task_id: 85\n",
            "INFO:Evaluation:Processing item 76 of 500. Task_id: 86\n",
            "INFO:Evaluation:Processing item 77 of 500. Task_id: 87\n",
            "INFO:Evaluation:Processing item 78 of 500. Task_id: 88\n",
            "INFO:Evaluation:Processing item 79 of 500. Task_id: 89\n",
            "INFO:Evaluation:Processing item 80 of 500. Task_id: 90\n",
            "INFO:Evaluation:Processing item 81 of 500. Task_id: 91\n",
            "INFO:Evaluation:Processing item 82 of 500. Task_id: 92\n",
            "INFO:Evaluation:Processing item 83 of 500. Task_id: 93\n",
            "INFO:Evaluation:Processing item 84 of 500. Task_id: 94\n",
            "INFO:Evaluation:Processing item 85 of 500. Task_id: 95\n",
            "INFO:Evaluation:Processing item 86 of 500. Task_id: 96\n",
            "INFO:Evaluation:Processing item 87 of 500. Task_id: 97\n",
            "INFO:Evaluation:Processing item 88 of 500. Task_id: 98\n",
            "INFO:Evaluation:Processing item 89 of 500. Task_id: 99\n",
            "INFO:Evaluation:Processing item 90 of 500. Task_id: 100\n",
            "INFO:Evaluation:Processing item 91 of 500. Task_id: 101\n",
            "INFO:Evaluation:Processing item 92 of 500. Task_id: 102\n",
            "INFO:Evaluation:Processing item 93 of 500. Task_id: 103\n",
            "INFO:Evaluation:Processing item 94 of 500. Task_id: 104\n",
            "INFO:Evaluation:Processing item 95 of 500. Task_id: 105\n",
            "INFO:Evaluation:Processing item 96 of 500. Task_id: 106\n",
            "INFO:Evaluation:Processing item 97 of 500. Task_id: 107\n",
            "INFO:Evaluation:Processing item 98 of 500. Task_id: 108\n",
            "INFO:Evaluation:Processing item 99 of 500. Task_id: 109\n",
            "INFO:Evaluation:Processing item 100 of 500. Task_id: 110\n",
            "INFO:Evaluation:Processing item 101 of 500. Task_id: 111\n",
            "INFO:Evaluation:Processing item 102 of 500. Task_id: 112\n",
            "INFO:Evaluation:Processing item 103 of 500. Task_id: 113\n",
            "INFO:Evaluation:Processing item 104 of 500. Task_id: 114\n",
            "INFO:Evaluation:Processing item 105 of 500. Task_id: 115\n",
            "INFO:Evaluation:Processing item 106 of 500. Task_id: 116\n",
            "INFO:Evaluation:Processing item 107 of 500. Task_id: 117\n",
            "INFO:Evaluation:Processing item 108 of 500. Task_id: 118\n",
            "INFO:Evaluation:Processing item 109 of 500. Task_id: 119\n",
            "INFO:Evaluation:Processing item 110 of 500. Task_id: 120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "0\n",
            "10090807060504030201\n",
            "1\n",
            "20019018017016015014013012011010090807060504030201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Evaluation:Processing item 111 of 500. Task_id: 121\n",
            "INFO:Evaluation:Processing item 112 of 500. Task_id: 122\n",
            "INFO:Evaluation:Processing item 113 of 500. Task_id: 123\n",
            "INFO:Evaluation:Processing item 114 of 500. Task_id: 124\n",
            "INFO:Evaluation:Processing item 115 of 500. Task_id: 125\n",
            "INFO:Evaluation:Processing item 116 of 500. Task_id: 126\n",
            "INFO:Evaluation:Processing item 117 of 500. Task_id: 127\n",
            "INFO:Evaluation:Processing item 118 of 500. Task_id: 128\n",
            "INFO:Evaluation:Processing item 119 of 500. Task_id: 129\n",
            "INFO:Evaluation:Processing item 120 of 500. Task_id: 130\n",
            "INFO:Evaluation:Processing item 121 of 500. Task_id: 131\n",
            "INFO:Evaluation:Processing item 122 of 500. Task_id: 132\n",
            "INFO:Evaluation:Processing item 123 of 500. Task_id: 133\n",
            "INFO:Evaluation:Processing item 124 of 500. Task_id: 134\n",
            "INFO:Evaluation:Processing item 125 of 500. Task_id: 135\n",
            "INFO:Evaluation:Processing item 126 of 500. Task_id: 136\n",
            "INFO:Evaluation:Processing item 127 of 500. Task_id: 137\n",
            "INFO:Evaluation:Processing item 128 of 500. Task_id: 138\n",
            "INFO:Evaluation:Processing item 129 of 500. Task_id: 139\n",
            "INFO:Evaluation:Processing item 130 of 500. Task_id: 140\n",
            "INFO:Evaluation:Processing item 131 of 500. Task_id: 141\n",
            "INFO:Evaluation:Processing item 132 of 500. Task_id: 142\n",
            "INFO:Evaluation:Processing item 133 of 500. Task_id: 143\n",
            "INFO:Evaluation:Processing item 134 of 500. Task_id: 144\n",
            "INFO:Evaluation:Processing item 135 of 500. Task_id: 145\n",
            "INFO:Evaluation:Processing item 136 of 500. Task_id: 146\n",
            "INFO:Evaluation:Processing item 137 of 500. Task_id: 147\n",
            "INFO:Evaluation:Processing item 138 of 500. Task_id: 148\n",
            "INFO:Evaluation:Processing item 139 of 500. Task_id: 149\n",
            "INFO:Evaluation:Processing item 140 of 500. Task_id: 150\n",
            "INFO:Evaluation:Processing item 141 of 500. Task_id: 151\n",
            "INFO:Evaluation:Processing item 142 of 500. Task_id: 152\n",
            "INFO:Evaluation:Processing item 143 of 500. Task_id: 153\n",
            "INFO:Evaluation:Processing item 144 of 500. Task_id: 154\n",
            "INFO:Evaluation:Processing item 145 of 500. Task_id: 155\n",
            "INFO:Evaluation:Processing item 146 of 500. Task_id: 156\n",
            "INFO:Evaluation:Processing item 147 of 500. Task_id: 157\n",
            "INFO:Evaluation:Processing item 148 of 500. Task_id: 158\n",
            "INFO:Evaluation:Processing item 149 of 500. Task_id: 159\n",
            "INFO:Evaluation:Processing item 150 of 500. Task_id: 160\n",
            "INFO:Evaluation:Processing item 151 of 500. Task_id: 161\n",
            "INFO:Evaluation:Processing item 152 of 500. Task_id: 162\n",
            "INFO:Evaluation:Processing item 153 of 500. Task_id: 163\n",
            "INFO:Evaluation:Processing item 154 of 500. Task_id: 164\n",
            "INFO:Evaluation:Processing item 155 of 500. Task_id: 165\n",
            "INFO:Evaluation:Processing item 156 of 500. Task_id: 166\n",
            "INFO:Evaluation:Processing item 157 of 500. Task_id: 167\n",
            "INFO:Evaluation:Processing item 158 of 500. Task_id: 168\n",
            "INFO:Evaluation:Processing item 159 of 500. Task_id: 169\n",
            "INFO:Evaluation:Processing item 160 of 500. Task_id: 170\n",
            "INFO:Evaluation:Processing item 161 of 500. Task_id: 171\n",
            "INFO:Evaluation:Processing item 162 of 500. Task_id: 172\n",
            "INFO:Evaluation:Processing item 163 of 500. Task_id: 173\n",
            "INFO:Evaluation:Processing item 164 of 500. Task_id: 174\n",
            "INFO:Evaluation:Processing item 165 of 500. Task_id: 175\n",
            "INFO:Evaluation:Processing item 166 of 500. Task_id: 176\n",
            "INFO:Evaluation:Processing item 167 of 500. Task_id: 177\n",
            "INFO:Evaluation:Processing item 168 of 500. Task_id: 178\n",
            "INFO:Evaluation:Processing item 169 of 500. Task_id: 179\n",
            "INFO:Evaluation:Processing item 170 of 500. Task_id: 180\n",
            "INFO:Evaluation:Processing item 171 of 500. Task_id: 181\n",
            "INFO:Evaluation:Processing item 172 of 500. Task_id: 182\n",
            "INFO:Evaluation:Processing item 173 of 500. Task_id: 183\n",
            "INFO:Evaluation:Processing item 174 of 500. Task_id: 184\n",
            "INFO:Evaluation:Processing item 175 of 500. Task_id: 185\n",
            "INFO:Evaluation:Processing item 176 of 500. Task_id: 186\n",
            "INFO:Evaluation:Processing item 177 of 500. Task_id: 187\n",
            "INFO:Evaluation:Processing item 178 of 500. Task_id: 188\n",
            "INFO:Evaluation:Processing item 179 of 500. Task_id: 189\n",
            "INFO:Evaluation:Processing item 180 of 500. Task_id: 190\n",
            "INFO:Evaluation:Processing item 181 of 500. Task_id: 191\n",
            "INFO:Evaluation:Processing item 182 of 500. Task_id: 192\n",
            "INFO:Evaluation:Processing item 183 of 500. Task_id: 193\n",
            "INFO:Evaluation:Processing item 184 of 500. Task_id: 194\n",
            "INFO:Evaluation:Processing item 185 of 500. Task_id: 195\n",
            "INFO:Evaluation:Processing item 186 of 500. Task_id: 196\n",
            "INFO:Evaluation:Processing item 187 of 500. Task_id: 197\n",
            "INFO:Evaluation:Processing item 188 of 500. Task_id: 198\n",
            "INFO:Evaluation:Processing item 189 of 500. Task_id: 199\n",
            "INFO:Evaluation:Processing item 190 of 500. Task_id: 200\n",
            "INFO:Evaluation:Processing item 191 of 500. Task_id: 201\n",
            "INFO:Evaluation:Processing item 192 of 500. Task_id: 202\n",
            "INFO:Evaluation:Processing item 193 of 500. Task_id: 203\n",
            "INFO:Evaluation:Processing item 194 of 500. Task_id: 204\n",
            "INFO:Evaluation:Processing item 195 of 500. Task_id: 205\n",
            "INFO:Evaluation:Processing item 196 of 500. Task_id: 206\n",
            "INFO:Evaluation:Processing item 197 of 500. Task_id: 207\n",
            "INFO:Evaluation:Processing item 198 of 500. Task_id: 208\n",
            "INFO:Evaluation:Processing item 199 of 500. Task_id: 209\n",
            "INFO:Evaluation:Processing item 200 of 500. Task_id: 210\n",
            "INFO:Evaluation:Processing item 201 of 500. Task_id: 211\n",
            "INFO:Evaluation:Processing item 202 of 500. Task_id: 212\n",
            "INFO:Evaluation:Processing item 203 of 500. Task_id: 213\n",
            "INFO:Evaluation:Processing item 204 of 500. Task_id: 214\n",
            "INFO:Evaluation:Processing item 205 of 500. Task_id: 215\n",
            "INFO:Evaluation:Processing item 206 of 500. Task_id: 216\n",
            "INFO:Evaluation:Processing item 207 of 500. Task_id: 217\n",
            "INFO:Evaluation:Processing item 208 of 500. Task_id: 218\n",
            "INFO:Evaluation:Processing item 209 of 500. Task_id: 219\n",
            "INFO:Evaluation:Processing item 210 of 500. Task_id: 220\n",
            "INFO:Evaluation:Processing item 211 of 500. Task_id: 221\n",
            "INFO:Evaluation:Processing item 212 of 500. Task_id: 222\n",
            "INFO:Evaluation:Processing item 213 of 500. Task_id: 223\n",
            "INFO:Evaluation:Processing item 214 of 500. Task_id: 224\n",
            "INFO:Evaluation:Processing item 215 of 500. Task_id: 225\n",
            "INFO:Evaluation:Processing item 216 of 500. Task_id: 226\n",
            "INFO:Evaluation:Processing item 217 of 500. Task_id: 227\n",
            "INFO:Evaluation:Processing item 218 of 500. Task_id: 228\n",
            "INFO:Evaluation:Processing item 219 of 500. Task_id: 229\n",
            "INFO:Evaluation:Processing item 220 of 500. Task_id: 230\n",
            "INFO:Evaluation:Processing item 221 of 500. Task_id: 231\n",
            "INFO:Evaluation:Processing item 222 of 500. Task_id: 232\n",
            "INFO:Evaluation:Processing item 223 of 500. Task_id: 233\n",
            "INFO:Evaluation:Processing item 224 of 500. Task_id: 234\n",
            "INFO:Evaluation:Processing item 225 of 500. Task_id: 235\n",
            "INFO:Evaluation:Processing item 226 of 500. Task_id: 236\n",
            "INFO:Evaluation:Processing item 227 of 500. Task_id: 237\n",
            "INFO:Evaluation:Processing item 228 of 500. Task_id: 238\n",
            "INFO:Evaluation:Processing item 229 of 500. Task_id: 239\n",
            "INFO:Evaluation:Processing item 230 of 500. Task_id: 240\n",
            "INFO:Evaluation:Processing item 231 of 500. Task_id: 241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "2\n",
            "0\n",
            "0\n",
            "False\n",
            "False\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Evaluation:Processing item 232 of 500. Task_id: 242\n",
            "INFO:Evaluation:Processing item 233 of 500. Task_id: 243\n",
            "INFO:Evaluation:Processing item 234 of 500. Task_id: 244\n",
            "INFO:Evaluation:Processing item 235 of 500. Task_id: 245\n",
            "INFO:Evaluation:Processing item 236 of 500. Task_id: 246\n",
            "INFO:Evaluation:Processing item 237 of 500. Task_id: 247\n",
            "INFO:Evaluation:Processing item 238 of 500. Task_id: 248\n",
            "INFO:Evaluation:Processing item 239 of 500. Task_id: 249\n",
            "INFO:Evaluation:Processing item 240 of 500. Task_id: 250\n",
            "INFO:Evaluation:Processing item 241 of 500. Task_id: 251\n",
            "INFO:Evaluation:Processing item 242 of 500. Task_id: 252\n",
            "INFO:Evaluation:Processing item 243 of 500. Task_id: 253\n",
            "INFO:Evaluation:Processing item 244 of 500. Task_id: 254\n",
            "INFO:Evaluation:Processing item 245 of 500. Task_id: 255\n",
            "INFO:Evaluation:Processing item 246 of 500. Task_id: 256\n",
            "INFO:Evaluation:Processing item 247 of 500. Task_id: 257\n",
            "INFO:Evaluation:Processing item 248 of 500. Task_id: 258\n",
            "INFO:Evaluation:Processing item 249 of 500. Task_id: 259\n",
            "INFO:Evaluation:Processing item 250 of 500. Task_id: 260\n",
            "INFO:Evaluation:Processing item 251 of 500. Task_id: 261\n",
            "INFO:Evaluation:Processing item 252 of 500. Task_id: 262\n",
            "INFO:Evaluation:Processing item 253 of 500. Task_id: 263\n",
            "INFO:Evaluation:Processing item 254 of 500. Task_id: 264\n",
            "INFO:Evaluation:Processing item 255 of 500. Task_id: 265\n",
            "INFO:Evaluation:Processing item 256 of 500. Task_id: 266\n",
            "INFO:Evaluation:Processing item 257 of 500. Task_id: 267\n",
            "INFO:Evaluation:Processing item 258 of 500. Task_id: 268\n",
            "INFO:Evaluation:Processing item 259 of 500. Task_id: 269\n",
            "INFO:Evaluation:Processing item 260 of 500. Task_id: 270\n",
            "INFO:Evaluation:Processing item 261 of 500. Task_id: 271\n",
            "INFO:Evaluation:Processing item 262 of 500. Task_id: 272\n",
            "INFO:Evaluation:Processing item 263 of 500. Task_id: 273\n",
            "INFO:Evaluation:Processing item 264 of 500. Task_id: 274\n",
            "INFO:Evaluation:Processing item 265 of 500. Task_id: 275\n",
            "INFO:Evaluation:Processing item 266 of 500. Task_id: 276\n",
            "INFO:Evaluation:Processing item 267 of 500. Task_id: 277\n",
            "INFO:Evaluation:Processing item 268 of 500. Task_id: 278\n",
            "INFO:Evaluation:Processing item 269 of 500. Task_id: 279\n",
            "INFO:Evaluation:Processing item 270 of 500. Task_id: 280\n",
            "INFO:Evaluation:Processing item 271 of 500. Task_id: 281\n",
            "INFO:Evaluation:Processing item 272 of 500. Task_id: 282\n",
            "INFO:Evaluation:Processing item 273 of 500. Task_id: 283\n",
            "INFO:Evaluation:Processing item 274 of 500. Task_id: 284\n",
            "INFO:Evaluation:Processing item 275 of 500. Task_id: 285\n",
            "INFO:Evaluation:Processing item 276 of 500. Task_id: 286\n",
            "INFO:Evaluation:Processing item 277 of 500. Task_id: 287\n",
            "INFO:Evaluation:Processing item 278 of 500. Task_id: 288\n",
            "INFO:Evaluation:Processing item 279 of 500. Task_id: 289\n",
            "INFO:Evaluation:Processing item 280 of 500. Task_id: 290\n",
            "INFO:Evaluation:Processing item 281 of 500. Task_id: 291\n",
            "INFO:Evaluation:Processing item 282 of 500. Task_id: 292\n",
            "INFO:Evaluation:Processing item 283 of 500. Task_id: 293\n",
            "INFO:Evaluation:Processing item 284 of 500. Task_id: 294\n",
            "INFO:Evaluation:Processing item 285 of 500. Task_id: 295\n",
            "INFO:Evaluation:Processing item 286 of 500. Task_id: 296\n",
            "INFO:Evaluation:Processing item 287 of 500. Task_id: 297\n",
            "INFO:Evaluation:Processing item 288 of 500. Task_id: 298\n",
            "INFO:Evaluation:Processing item 289 of 500. Task_id: 299\n",
            "INFO:Evaluation:Processing item 290 of 500. Task_id: 300\n",
            "INFO:Evaluation:Processing item 291 of 500. Task_id: 301\n",
            "INFO:Evaluation:Processing item 292 of 500. Task_id: 302\n",
            "INFO:Evaluation:Processing item 293 of 500. Task_id: 303\n",
            "INFO:Evaluation:Processing item 294 of 500. Task_id: 304\n",
            "INFO:Evaluation:Processing item 295 of 500. Task_id: 305\n",
            "INFO:Evaluation:Processing item 296 of 500. Task_id: 306\n",
            "INFO:Evaluation:Processing item 297 of 500. Task_id: 307\n",
            "INFO:Evaluation:Processing item 298 of 500. Task_id: 308\n",
            "INFO:Evaluation:Processing item 299 of 500. Task_id: 309\n",
            "INFO:Evaluation:Processing item 300 of 500. Task_id: 310\n",
            "INFO:Evaluation:Processing item 301 of 500. Task_id: 311\n",
            "INFO:Evaluation:Processing item 302 of 500. Task_id: 312\n",
            "INFO:Evaluation:Processing item 303 of 500. Task_id: 313\n",
            "INFO:Evaluation:Processing item 304 of 500. Task_id: 314\n",
            "INFO:Evaluation:Processing item 305 of 500. Task_id: 315\n",
            "INFO:Evaluation:Processing item 306 of 500. Task_id: 316\n",
            "INFO:Evaluation:Processing item 307 of 500. Task_id: 317\n",
            "INFO:Evaluation:Processing item 308 of 500. Task_id: 318\n",
            "INFO:Evaluation:Processing item 309 of 500. Task_id: 319\n",
            "INFO:Evaluation:Processing item 310 of 500. Task_id: 320\n",
            "INFO:Evaluation:Processing item 311 of 500. Task_id: 321\n",
            "INFO:Evaluation:Processing item 312 of 500. Task_id: 322\n",
            "INFO:Evaluation:Processing item 313 of 500. Task_id: 323\n",
            "INFO:Evaluation:Processing item 314 of 500. Task_id: 324\n",
            "INFO:Evaluation:Processing item 315 of 500. Task_id: 325\n",
            "INFO:Evaluation:Processing item 316 of 500. Task_id: 326\n",
            "INFO:Evaluation:Processing item 317 of 500. Task_id: 327\n",
            "INFO:Evaluation:Processing item 318 of 500. Task_id: 328\n",
            "INFO:Evaluation:Processing item 319 of 500. Task_id: 329\n",
            "INFO:Evaluation:Processing item 320 of 500. Task_id: 330\n",
            "INFO:Evaluation:Processing item 321 of 500. Task_id: 331\n",
            "INFO:Evaluation:Processing item 322 of 500. Task_id: 332\n",
            "INFO:Evaluation:Processing item 323 of 500. Task_id: 333\n",
            "INFO:Evaluation:Processing item 324 of 500. Task_id: 334\n",
            "INFO:Evaluation:Processing item 325 of 500. Task_id: 335\n",
            "INFO:Evaluation:Processing item 326 of 500. Task_id: 336\n",
            "INFO:Evaluation:Processing item 327 of 500. Task_id: 337\n",
            "INFO:Evaluation:Processing item 328 of 500. Task_id: 338\n",
            "INFO:Evaluation:Processing item 329 of 500. Task_id: 339\n",
            "INFO:Evaluation:Processing item 330 of 500. Task_id: 340\n",
            "INFO:Evaluation:Processing item 331 of 500. Task_id: 341\n",
            "INFO:Evaluation:Processing item 332 of 500. Task_id: 342\n",
            "INFO:Evaluation:Processing item 333 of 500. Task_id: 343\n",
            "INFO:Evaluation:Processing item 334 of 500. Task_id: 344\n",
            "INFO:Evaluation:Processing item 335 of 500. Task_id: 345\n",
            "INFO:Evaluation:Processing item 336 of 500. Task_id: 346\n",
            "INFO:Evaluation:Processing item 337 of 500. Task_id: 347\n",
            "INFO:Evaluation:Processing item 338 of 500. Task_id: 348\n",
            "INFO:Evaluation:Processing item 339 of 500. Task_id: 349\n",
            "INFO:Evaluation:Processing item 340 of 500. Task_id: 350\n",
            "INFO:Evaluation:Processing item 341 of 500. Task_id: 351\n",
            "INFO:Evaluation:Processing item 342 of 500. Task_id: 352\n",
            "INFO:Evaluation:Processing item 343 of 500. Task_id: 353\n",
            "INFO:Evaluation:Processing item 344 of 500. Task_id: 354\n",
            "INFO:Evaluation:Processing item 345 of 500. Task_id: 355\n",
            "INFO:Evaluation:Processing item 346 of 500. Task_id: 356\n",
            "INFO:Evaluation:Processing item 347 of 500. Task_id: 357\n",
            "INFO:Evaluation:Processing item 348 of 500. Task_id: 358\n",
            "INFO:Evaluation:Processing item 349 of 500. Task_id: 359\n",
            "INFO:Evaluation:Processing item 350 of 500. Task_id: 360\n",
            "INFO:Evaluation:Processing item 351 of 500. Task_id: 361\n",
            "INFO:Evaluation:Processing item 352 of 500. Task_id: 362\n",
            "INFO:Evaluation:Processing item 353 of 500. Task_id: 363\n",
            "INFO:Evaluation:Processing item 354 of 500. Task_id: 364\n",
            "INFO:Evaluation:Processing item 355 of 500. Task_id: 365\n",
            "INFO:Evaluation:Processing item 356 of 500. Task_id: 366\n",
            "INFO:Evaluation:Processing item 357 of 500. Task_id: 367\n",
            "INFO:Evaluation:Processing item 358 of 500. Task_id: 368\n",
            "INFO:Evaluation:Processing item 359 of 500. Task_id: 369\n",
            "INFO:Evaluation:Processing item 360 of 500. Task_id: 370\n",
            "INFO:Evaluation:Processing item 361 of 500. Task_id: 371\n",
            "INFO:Evaluation:Processing item 362 of 500. Task_id: 372\n",
            "INFO:Evaluation:Processing item 363 of 500. Task_id: 373\n",
            "INFO:Evaluation:Processing item 364 of 500. Task_id: 374\n",
            "INFO:Evaluation:Processing item 365 of 500. Task_id: 375\n",
            "INFO:Evaluation:Processing item 366 of 500. Task_id: 376\n",
            "INFO:Evaluation:Processing item 367 of 500. Task_id: 377\n",
            "INFO:Evaluation:Processing item 368 of 500. Task_id: 378\n",
            "INFO:Evaluation:Processing item 369 of 500. Task_id: 379\n",
            "INFO:Evaluation:Processing item 370 of 500. Task_id: 380\n",
            "INFO:Evaluation:Processing item 371 of 500. Task_id: 381\n",
            "INFO:Evaluation:Processing item 372 of 500. Task_id: 382\n",
            "INFO:Evaluation:Processing item 373 of 500. Task_id: 383\n",
            "INFO:Evaluation:Processing item 374 of 500. Task_id: 384\n",
            "INFO:Evaluation:Processing item 375 of 500. Task_id: 385\n",
            "INFO:Evaluation:Processing item 376 of 500. Task_id: 386\n",
            "INFO:Evaluation:Processing item 377 of 500. Task_id: 387\n",
            "INFO:Evaluation:Processing item 378 of 500. Task_id: 388\n",
            "INFO:Evaluation:Processing item 379 of 500. Task_id: 389\n",
            "INFO:Evaluation:Processing item 380 of 500. Task_id: 390\n",
            "INFO:Evaluation:Processing item 381 of 500. Task_id: 391\n",
            "INFO:Evaluation:Processing item 382 of 500. Task_id: 392\n",
            "INFO:Evaluation:Processing item 383 of 500. Task_id: 393\n",
            "INFO:Evaluation:Processing item 384 of 500. Task_id: 394\n",
            "INFO:Evaluation:Processing item 385 of 500. Task_id: 395\n",
            "INFO:Evaluation:Processing item 386 of 500. Task_id: 396\n",
            "INFO:Evaluation:Processing item 387 of 500. Task_id: 397\n",
            "INFO:Evaluation:Processing item 388 of 500. Task_id: 398\n",
            "INFO:Evaluation:Processing item 389 of 500. Task_id: 399\n",
            "INFO:Evaluation:Processing item 390 of 500. Task_id: 400\n",
            "INFO:Evaluation:Processing item 391 of 500. Task_id: 401\n",
            "INFO:Evaluation:Processing item 392 of 500. Task_id: 402\n",
            "INFO:Evaluation:Processing item 393 of 500. Task_id: 403\n",
            "INFO:Evaluation:Processing item 394 of 500. Task_id: 404\n",
            "INFO:Evaluation:Processing item 395 of 500. Task_id: 405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n",
            "74\n",
            "18\n",
            "2\n",
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Evaluation:Processing item 396 of 500. Task_id: 406\n",
            "INFO:Evaluation:Processing item 397 of 500. Task_id: 407\n",
            "INFO:Evaluation:Processing item 398 of 500. Task_id: 408\n",
            "INFO:Evaluation:Processing item 399 of 500. Task_id: 409\n",
            "INFO:Evaluation:Processing item 400 of 500. Task_id: 410\n",
            "INFO:Evaluation:Processing item 401 of 500. Task_id: 411\n",
            "INFO:Evaluation:Processing item 402 of 500. Task_id: 412\n",
            "INFO:Evaluation:Processing item 403 of 500. Task_id: 413\n",
            "INFO:Evaluation:Processing item 404 of 500. Task_id: 414\n",
            "INFO:Evaluation:Processing item 405 of 500. Task_id: 415\n",
            "INFO:Evaluation:Processing item 406 of 500. Task_id: 416\n",
            "INFO:Evaluation:Processing item 407 of 500. Task_id: 417\n",
            "INFO:Evaluation:Processing item 408 of 500. Task_id: 418\n",
            "INFO:Evaluation:Processing item 409 of 500. Task_id: 419\n",
            "INFO:Evaluation:Processing item 410 of 500. Task_id: 420\n",
            "INFO:Evaluation:Processing item 411 of 500. Task_id: 421\n",
            "INFO:Evaluation:Processing item 412 of 500. Task_id: 422\n",
            "INFO:Evaluation:Processing item 413 of 500. Task_id: 423\n",
            "INFO:Evaluation:Processing item 414 of 500. Task_id: 424\n",
            "INFO:Evaluation:Processing item 415 of 500. Task_id: 425\n",
            "INFO:Evaluation:Processing item 416 of 500. Task_id: 426\n",
            "INFO:Evaluation:Processing item 417 of 500. Task_id: 427\n",
            "INFO:Evaluation:Processing item 418 of 500. Task_id: 428\n",
            "INFO:Evaluation:Processing item 419 of 500. Task_id: 429\n",
            "INFO:Evaluation:Processing item 420 of 500. Task_id: 430\n",
            "INFO:Evaluation:Processing item 421 of 500. Task_id: 431\n",
            "INFO:Evaluation:Processing item 422 of 500. Task_id: 432\n",
            "INFO:Evaluation:Processing item 423 of 500. Task_id: 433\n",
            "INFO:Evaluation:Processing item 424 of 500. Task_id: 434\n",
            "INFO:Evaluation:Processing item 425 of 500. Task_id: 435\n",
            "INFO:Evaluation:Processing item 426 of 500. Task_id: 436\n",
            "INFO:Evaluation:Processing item 427 of 500. Task_id: 437\n",
            "INFO:Evaluation:Processing item 428 of 500. Task_id: 438\n",
            "INFO:Evaluation:Processing item 429 of 500. Task_id: 439\n",
            "INFO:Evaluation:Processing item 430 of 500. Task_id: 440\n",
            "INFO:Evaluation:Processing item 431 of 500. Task_id: 441\n",
            "INFO:Evaluation:Processing item 432 of 500. Task_id: 442\n",
            "INFO:Evaluation:Processing item 433 of 500. Task_id: 443\n",
            "INFO:Evaluation:Processing item 434 of 500. Task_id: 444\n",
            "INFO:Evaluation:Processing item 435 of 500. Task_id: 445\n",
            "INFO:Evaluation:Processing item 436 of 500. Task_id: 446\n",
            "INFO:Evaluation:Processing item 437 of 500. Task_id: 447\n",
            "INFO:Evaluation:Processing item 438 of 500. Task_id: 448\n",
            "INFO:Evaluation:Processing item 439 of 500. Task_id: 449\n",
            "INFO:Evaluation:Processing item 440 of 500. Task_id: 450\n",
            "INFO:Evaluation:Processing item 441 of 500. Task_id: 451\n",
            "INFO:Evaluation:Processing item 442 of 500. Task_id: 452\n",
            "INFO:Evaluation:Processing item 443 of 500. Task_id: 453\n",
            "INFO:Evaluation:Processing item 444 of 500. Task_id: 454\n",
            "INFO:Evaluation:Processing item 445 of 500. Task_id: 455\n",
            "INFO:Evaluation:Processing item 446 of 500. Task_id: 456\n",
            "INFO:Evaluation:Processing item 447 of 500. Task_id: 457\n",
            "INFO:Evaluation:Processing item 448 of 500. Task_id: 458\n",
            "INFO:Evaluation:Processing item 449 of 500. Task_id: 459\n",
            "INFO:Evaluation:Processing item 450 of 500. Task_id: 460\n",
            "INFO:Evaluation:Processing item 451 of 500. Task_id: 461\n",
            "INFO:Evaluation:Processing item 452 of 500. Task_id: 462\n",
            "INFO:Evaluation:Processing item 453 of 500. Task_id: 463\n",
            "INFO:Evaluation:Processing item 454 of 500. Task_id: 464\n",
            "INFO:Evaluation:Processing item 455 of 500. Task_id: 465\n",
            "INFO:Evaluation:Processing item 456 of 500. Task_id: 466\n",
            "INFO:Evaluation:Processing item 457 of 500. Task_id: 467\n",
            "INFO:Evaluation:Processing item 458 of 500. Task_id: 468\n",
            "INFO:Evaluation:Processing item 459 of 500. Task_id: 469\n",
            "INFO:Evaluation:Processing item 460 of 500. Task_id: 470\n",
            "INFO:Evaluation:Processing item 461 of 500. Task_id: 471\n",
            "INFO:Evaluation:Processing item 462 of 500. Task_id: 472\n",
            "INFO:Evaluation:Processing item 463 of 500. Task_id: 473\n",
            "INFO:Evaluation:Processing item 464 of 500. Task_id: 474\n",
            "INFO:Evaluation:Processing item 465 of 500. Task_id: 475\n",
            "INFO:Evaluation:Processing item 466 of 500. Task_id: 476\n",
            "INFO:Evaluation:Processing item 467 of 500. Task_id: 477\n",
            "INFO:Evaluation:Processing item 468 of 500. Task_id: 478\n",
            "INFO:Evaluation:Processing item 469 of 500. Task_id: 479\n",
            "INFO:Evaluation:Processing item 470 of 500. Task_id: 480\n",
            "INFO:Evaluation:Processing item 471 of 500. Task_id: 481\n",
            "INFO:Evaluation:Processing item 472 of 500. Task_id: 482\n",
            "INFO:Evaluation:Processing item 473 of 500. Task_id: 483\n",
            "INFO:Evaluation:Processing item 474 of 500. Task_id: 484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23, 12, 5, 12, 4, 81, 3, 56, 2, 95]\n",
            "[39, 34, 87, 24, 73, 22, 68]\n",
            "[96, 32, 82, 30, 83, 16, 74]\n",
            "-1 is negative\n",
            "4 is not negative\n",
            "5 is not negative\n",
            "-6 is negative\n",
            "-1 is negative\n",
            "4 is not negative\n",
            "5 is not negative\n",
            "-6 is negative\n",
            "-1 is negative\n",
            "-2 is negative\n",
            "3 is not negative\n",
            "4 is not negative\n",
            "-7 is negative\n",
            "-6 is negative\n",
            "8 is not negative\n",
            "9 is not negative\n",
            "False\n",
            "False\n",
            "False\n",
            "pollgon\n",
            "aharaater\n",
            "python\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Evaluation:Processing item 475 of 500. Task_id: 485\n",
            "INFO:Evaluation:Processing item 476 of 500. Task_id: 486\n",
            "INFO:Evaluation:Processing item 477 of 500. Task_id: 487\n",
            "INFO:Evaluation:Processing item 478 of 500. Task_id: 488\n",
            "INFO:Evaluation:Processing item 479 of 500. Task_id: 489\n",
            "INFO:Evaluation:Processing item 480 of 500. Task_id: 490\n",
            "INFO:Evaluation:Processing item 481 of 500. Task_id: 491\n",
            "INFO:Evaluation:Processing item 482 of 500. Task_id: 492\n",
            "INFO:Evaluation:Processing item 483 of 500. Task_id: 493\n",
            "INFO:Evaluation:Processing item 484 of 500. Task_id: 494\n",
            "INFO:Evaluation:Processing item 485 of 500. Task_id: 495\n",
            "INFO:Evaluation:Processing item 486 of 500. Task_id: 496\n",
            "INFO:Evaluation:Processing item 487 of 500. Task_id: 497\n",
            "INFO:Evaluation:Processing item 488 of 500. Task_id: 498\n",
            "INFO:Evaluation:Processing item 489 of 500. Task_id: 499\n",
            "INFO:Evaluation:Processing item 490 of 500. Task_id: 500\n",
            "INFO:Evaluation:Processing item 491 of 500. Task_id: 501\n",
            "INFO:Evaluation:Processing item 492 of 500. Task_id: 502\n",
            "INFO:Evaluation:Processing item 493 of 500. Task_id: 503\n",
            "INFO:Evaluation:Processing item 494 of 500. Task_id: 504\n",
            "INFO:Evaluation:Processing item 495 of 500. Task_id: 505\n",
            "INFO:Evaluation:Processing item 496 of 500. Task_id: 506\n",
            "INFO:Evaluation:Processing item 497 of 500. Task_id: 507\n",
            "INFO:Evaluation:Processing item 498 of 500. Task_id: 508\n",
            "INFO:Evaluation:Processing item 499 of 500. Task_id: 509\n",
            "INFO:Evaluation:Processing item 500 of 500. Task_id: 510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute metric"
      ],
      "metadata": {
        "id": "tQti65L9wUBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Passing all 3 test cases"
      ],
      "metadata": {
        "id": "Qh-VsSRby7Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_all_test_cases = [1 if acc == 1 else 0 for acc in acc_list]"
      ],
      "metadata": {
        "id": "ffFr7Ke0yUET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import builtins"
      ],
      "metadata": {
        "id": "cI1ZZFLp0HKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Tasks Solved: {builtins.sum(acc_all_test_cases)/len(acc_all_test_cases)*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yW6hYByz5Qd",
        "outputId": "af8b2d29-8d0a-45ca-c467-d2a41bd7b64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tasks Solved: 14.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Passing at least 2 test cases"
      ],
      "metadata": {
        "id": "TCfP25pB0t7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_all_test_cases = [1 if acc > 0.5 else 0 for acc in acc_list]"
      ],
      "metadata": {
        "id": "ZBn1eVtm0xb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Tasks Solved: {builtins.sum(acc_all_test_cases)/len(acc_all_test_cases)*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHG5KAqo01rP",
        "outputId": "6ff203a5-adb2-4342-b918-1a85fb61f3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tasks Solved: 19.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Passing at least 1 test case"
      ],
      "metadata": {
        "id": "J8QdMDGe1DwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_all_test_cases = [1 if acc > 0 else 0 for acc in acc_list]"
      ],
      "metadata": {
        "id": "EL1JeETT1A2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Tasks Solved: {builtins.sum(acc_all_test_cases)/len(acc_all_test_cases)*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFQRrsTf1GSx",
        "outputId": "b8817068-f1ac-48a0-ab2b-51314ea929d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tasks Solved: 26.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pass @k\n",
        "\n",
        "The pass@k is the fraction of prompts for which the model succeeded in this sense.\n",
        "\n",
        "For example, if Pass@5 is 80%, it means that for 80% of the queries, the system returned at least one relevant document among the top 5 results."
      ],
      "metadata": {
        "id": "mcC-GaUdZulT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HF_ALLOW_CODE_EVAL\"] = \"1\""
      ],
      "metadata": {
        "id": "2vdNOJEid0HI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\" # => solve colab error: NotImplementedError: A UTF-8 locale is required. Got ANSI_X3.4-1968"
      ],
      "metadata": {
        "id": "Hw2dpzWgeACY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8G3dclBdlZK",
        "outputId": "9d51366f-7b35-4e67-e74a-8ab68d3fe430"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.11.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.11.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pass_k_metric(test_cases: list[list], candidates: list[list], k: list) -> tuple[dict, dict]:\n",
        "  '''The Code Eval metric calculates how good are predictions given a set of references\n",
        "  https://huggingface.co/spaces/evaluate-metric/code_eval\n",
        "\n",
        "  Args: \n",
        "    test_cases\n",
        "    candidates\n",
        "    k\n",
        "  Returns:\n",
        "    (dict, dict)\n",
        "  '''\n",
        "  # Join test cases into a single string.\n",
        "  test_cases_joined = ['\\n'.join(test) for test in test_cases]\n",
        "  pass_at_k, results = code_eval.compute(references=test_cases_joined, predictions=candidates, k=k)\n",
        "  return pass_at_k, results"
      ],
      "metadata": {
        "id": "obQ6e6N4mfY1"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/CSCI544/Project/codet5-large-ntp-py-multiple-sentences-pred.csv')"
      ],
      "metadata": {
        "id": "M5ft43daodWH"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pass_k_test = []\n",
        "pass_k_predictions = []\n",
        "for test, pred in zip(df['test_list'], df['prediction']):\n",
        "    pass_k_test.append(eval(test))\n",
        "    pass_k_predictions.append(eval(pred))"
      ],
      "metadata": {
        "id": "ueQ1wVJjogm8"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pass_k_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0k6UK9GrtaS",
        "outputId": "e97c9898-94d5-44fc-f8fa-0a03cb3f66ab"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['assert remove_Occ(\"hello\",\"l\") == \"heo\"',\n",
              " 'assert remove_Occ(\"abcda\",\"a\") == \"bcd\"',\n",
              " 'assert remove_Occ(\"PHP\",\"P\") == \"H\"']"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pass_at_k, results = compute_pass_k_metric(pass_k_test, pass_k_predictions, [1,2,5, 80])"
      ],
      "metadata": {
        "id": "nZB5ifvRrjKE"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pass_at_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mioKrUpQsq_F",
        "outputId": "acb561c8-ab5c-48ab-a868-f2a42b1e9a36"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pass@1': 0.0, 'pass@2': 0.0, 'pass@5': 0.0, 'pass@80': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a = [i[i.find('def'):] for i in list_of_outputs]"
      ],
      "metadata": {
        "id": "QIKtO9QMccv7"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from evaluate import load\n",
        "# code_eval = load(\"code_eval\")\n",
        "# test_cases = [\"assert add(2,3)==5\"]\n",
        "# candidates = [[\"def add(a,b): return a*b\", \"def add(a, b): return a+b\", \"def add(a, b): return a-b\"]]\n",
        "# test_cases_2 = ['assert remove_Occ(\"hello\",\"l\") == \"heo\"\\nassert remove_Occ(\"abcda\",\"a\") == \"bcd\"\\nassert remove_Occ(\"PHP\",\"P\") == \"H\"']\n",
        "# candidates_2 = [a]"
      ],
      "metadata": {
        "id": "nZjZA_XaPeSM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from evaluate import load\n",
        "# code_eval = load(\"code_eval\")\n",
        "# test_cases = [\"assert add(2,3)==5\"]\n",
        "# candidates = [[\"def add(a,b): return a*b\", \"def add(a, b): return a+b\", \"def add(a, b): return a-b\"]]\n",
        "# test_cases_2 = ['assert remove_Occ(\"hello\",\"l\") == \"heo\"\\nassert remove_Occ(\"abcda\",\"a\") == \"bcd\"\\nassert remove_Occ(\"PHP\",\"P\") == \"H\"']\n",
        "# candidates_2 = [a[:-1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "k_YGyx9J2Htz",
        "outputId": "de5f6227-b9d5-4683-f145-b2ca8ee7af49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-07d4e94f8312>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcode_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"assert add(2,3)==5\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"def add(a,b): return a*b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"def add(a, b): return a+b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"def add(a, b): return a-b\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_cases_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'assert remove_Occ(\"hello\",\"l\") == \"heo\"\\nassert remove_Occ(\"abcda\",\"a\") == \"bcd\"\\nassert remove_Occ(\"PHP\",\"P\") == \"H\"'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluate'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TO DO:\n",
        "\n",
        " - [x] Compare performance with 0, 1, 2 or 3 test cases\n",
        " - [ ] Split error types in: CompileError, RuntimeError, FailedTest, and PassedTest"
      ],
      "metadata": {
        "id": "tOXaDELzaSx5"
      }
    }
  ]
}